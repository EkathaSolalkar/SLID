{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNSOuLs1D0OZUDTp9N+4lKi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"usXOCuw9Z_Ct"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# Load the data from the CSV file\n","data = pd.read_csv('/content/drive/MyDrive/mini project/MFCC.csv')\n","\n","# Extract features and labels\n","features = data.drop('label_list', axis=1).values\n","labels = data['label_list'].values\n","\n","# Convert labels to integers using LabelEncoder\n","label_encoder = LabelEncoder()\n","labels = label_encoder.fit_transform(labels)\n","\n","# Split the data into training and testing sets\n","x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n","\n","# Normalize the features to range [0, 1]\n","x_train = x_train.astype('float32') / np.max(features)\n","x_test = x_test.astype('float32') / np.max(features)\n","\n","# If the data is in 2D format, reshape it to 3D (num_samples, num_timesteps, num_features)\n","# Example: x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 1)\n","\n","# Convert labels to one-hot encoding\n","num_classes = len(np.unique(labels))\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","# Create the CNN model\n","model = keras.Sequential([\n","    layers.Reshape((12, 1), input_shape=(12,)),  # Reshape input for CNN\n","    layers.Conv1D(32, 3, activation='relu', padding='same'),\n","    layers.MaxPooling1D(pool_size=2),\n","    layers.Conv1D(64, 3, activation='relu', padding='same'),\n","    layers.MaxPooling1D(pool_size=2),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","batch_size = 16\n","epochs = 20\n","model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print('Test accuracy:', accuracy)"]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","model1 = Sequential()\n","model1.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n","model1.add(Dense(64, activation='relu'))\n","model1.add(Dense(1, activation='sigmoid'))\n","\n"],"metadata":{"id":"5GOpuOssaE5l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","# Instantiate the LabelEncoder\n","label_encoder = LabelEncoder()\n","# Convert string labels to numeric values\n","y_train = label_encoder.fit_transform(y_train)"],"metadata":{"id":"PMabvjCgaGWJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","label_encoder = LabelEncoder()\n","y_test_encoded = label_encoder.fit_transform(y_test)"],"metadata":{"id":"LQHgFsECaH3i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model1.fit(X_train, y_train, epochs=10, batch_size=32)\n"],"metadata":{"id":"z4qQXht6aJrI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lizfqW2uaY9A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import keras\n","from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","\n","# Dummy data for illustration purposes\n","# Replace this with your actual data\n","num_samples = 1000\n","num_timesteps = 20\n","num_features = 13\n","num_languages = 5\n","\n","# Generate random input data and labels\n","X = np.random.rand(num_samples, num_timesteps, num_features)\n","y = np.random.randint(0, num_languages, size=(num_samples,))\n","\n","# Convert labels to one-hot encoding\n","y_one_hot = to_categorical(y, num_languages)\n","\n","# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(units=64, input_shape=(num_timesteps, num_features)))\n","model.add(Dropout(0.5))\n","model.add(Dense(units=num_languages, activation='softmax'))\n","\n","# Compile the model\n","learning_rate = 0.001\n","optimizer = Adam(learning_rate)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","# Train the model\n","batch_size = 32\n","epochs = 10\n","model.fit(X, y_one_hot, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n","\n","# Now you can use the trained model to predict the language of new audio samples.\n","# Make sure to preprocess the audio data appropriately before feeding it to the model.\n"],"metadata":{"id":"Snnyo66KaY6G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# cnn"],"metadata":{"id":"JHtl3Tc6lAHs"}},{"cell_type":"code","source":["import numpy as np\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","\n","# Dummy data for illustration purposes\n","# Replace this with your actual data\n","num_samples = 1000\n","num_frames = 20  # Number of time frames in the spectrogram\n","num_features = 40  # Number of frequency bins in the spectrogram\n","num_languages = 5\n","\n","# Generate random input data and labels\n","X = np.random.rand(num_samples, num_frames, num_features, 1)  # Add an extra dimension for the channel\n","y = np.random.randint(0, num_languages, size=(num_samples,))\n","\n","# Convert labels to one-hot encoding\n","y_one_hot = to_categorical(y, num_languages)\n","\n","# Build the CNN model\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(num_frames, num_features, 1)))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_languages, activation='softmax'))\n","\n","# Compile the model\n","learning_rate = 0.001\n","optimizer = Adam(learning_rate)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","\n","# Train the model\n","batch_size = 32\n","epochs = 10\n","model.fit(X, y_one_hot, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n","\n","# Now you can use the trained model to predict the language of new audio samples.\n","# Make sure to preprocess the audio data appropriately to generate spectrograms\n","# and convert the data into suitable input format compatible with the model.\n"],"metadata":{"id":"SzGkUtJMlCFj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model on the test set\n","loss, accuracy = model.evaluate(X_test, y_test_encoded, verbose=0)\n","print('Test loss:', loss)\n","print('Test accuracy:', accuracy)\n"],"metadata":{"id":"5eQ9h_CbmQD6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# audio to spectrogram"],"metadata":{"id":"4Dzj81EbrY0X"}},{"cell_type":"code","source":["pip install librosa matplotlib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0hPn96HrYe7","executionInfo":{"status":"ok","timestamp":1690349507557,"user_tz":-330,"elapsed":9861,"user":{"displayName":"Ektha Solalkar","userId":"16983693407731223341"}},"outputId":"036f97bd-3627-4e49-998c-6826a6d1e2b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.0.post2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.0)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.22.4)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.10.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.56.4)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.6.0)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.5)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.7.1)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.41.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (67.7.2)\n","Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch<1.7,>=1.0->librosa) (2.27.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch<1.7,>=1.0->librosa) (3.4)\n"]}]},{"cell_type":"code","source":["import librosa\n","import librosa.display\n","import matplotlib.pyplot as plt"],"metadata":{"id":"qfaLxXWCrYbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["audio_file_path = 'path/to/your/audio/file.wav'\n","waveform, sr = librosa.load(audio_file_path, sr=None)  # sr=None to use the original sampling rate\n"],"metadata":{"id":"UAh3Iyd-rmP3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_fft = 2048  # Number of FFT points (window size)\n","hop_length = 512  # Number of samples between successive frames (frame shift)\n","spectrogram = librosa.stft(waveform, n_fft=n_fft, hop_length=hop_length)\n","magnitude_spectrogram = np.abs(spectrogram)\n"],"metadata":{"id":"tnaG1HgGrpq2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_magnitude_spectrogram = librosa.amplitude_to_db(magnitude_spectrogram, ref=np.max)\n"],"metadata":{"id":"oKLeGpaYrsIO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["librosa.display.specshow(log_magnitude_spectrogram, sr=sr, hop_length=hop_length, x_axis='time', y_axis='linear')\n","plt.colorbar(format='%+2.0f dB')\n","plt.title('Spectrogram')\n","plt.show()\n"],"metadata":{"id":"we1QEuzlrt1Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# lstm"],"metadata":{"id":"nftCZxfFtjMi"}},{"cell_type":"code","source":["from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Dropout\n","\n","model = Sequential([\n","    LSTM(123, return_sequences=False, input_shape=(40,1)),\n","    Dense(64, activation='relu'),\n","    Dropout(0.2),\n","    Dense(32, activation='relu'),\n","    Dropout(0.2),\n","    Dense(7, activation='softmax')\n","])\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"metadata":{"id":"adhooiUtti0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(X, y, validation_split=0.2, epochs=100, batch_size=512, shuffle=True)"],"metadata":{"id":"ZRziv46rtm0u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = list(range(100))\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","plt.plot(epochs, acc, label='train accuracy')\n","plt.plot(epochs, val_acc, label='val accuracy')\n","plt.xlabel('epochs')\n","plt.ylabel('accuracy')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"WUbpkPcltqsG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.plot(epochs, loss, label='train loss')\n","plt.plot(epochs, val_loss, label='val loss')\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"DvFo0m2Vtu8n"},"execution_count":null,"outputs":[]}]}